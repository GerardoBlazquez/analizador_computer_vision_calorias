# Analizador de Calor√≠as (Pre-Alpha)

Sistema modular basado en **Deep Learning (CNN + Transfer Learning)** para detectar si una imagen contiene **comida** o **no comida**, y clasificarla posteriormente en m√∫ltiples categor√≠as usando un **pipeline en cascada**.

> **Versi√≥n Beta disponible:**  
> La versi√≥n funcional en producci√≥n de este sistema se encuentra desplegada en mi portfolio personal: https://gcodev.es/  
>  
> Esta versi√≥n incluye una interfaz interactiva, backend operativo y mejoras respecto a este repositorio, que act√∫a como **base t√©cnica y experimental** del proyecto.

---
---
##  Resumen

Este proyecto implementa una arquitectura en **cascada de tres capas**:

-  **Filtro binario**: clasificaci√≥n `food` vs `no_food`
-  **Clasificador de alimentos**: 121 clases (Food-101 ampliado)
-  **Clasificador no-food**: 22 categor√≠as (personas, animales, paisajes, objetos...)

Incluye adem√°s un m√≥dulo de **estimaci√≥n nutricional** (calor√≠as y macronutrientes) basado en un CSV nutricional.

Se proporcionan:
- Notebooks reproducibles  
- Scripts de entrenamiento e inferencia  
- Backend FastAPI  
- UI Gradio  
- Docker para despliegue

### Notebooks

Puedes ejecutar y descargar los notebooks desde este repositorio:

- [Demo Analizador de Calor√≠as (Colab-ready)](notebooks/analizador_de_calor√≠as_computer_vision.ipynb)

Ejecutar directamente en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](
https://colab.research.google.com/github/TU_USUARIO/TU_REPO/blob/main/notebooks/analizador_calorias_computer_vision.ipynb
)

---

## Objetivo

Crear un sistema:
- Reproducible y modular
- Preparado para producci√≥n
- F√°cilmente extensible (nuevas clases, modelos o fuentes de datos)
- Capaz de integrarse en aplicaciones externas (mobile / web / IoT)

---

## Tabla de contenidos

- [Descripci√≥n](#descripci√≥n)
- [Objetivo](#objetivo)
- [Arquitectura](#arquitectura)
- [Caracter√≠sticas](#caracter√≠sticas)
- [Estructura del repositorio](#estructura-del-repositorio)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Entrenamiento](#entrenamiento)
- [Inferencia](#inferencia)
- [API (FastAPI)](#api-fastapi)
- [Interfaz Gradio](#interfaz-gradio)
- [Docker](#docker)
- [Modelos y datos](#modelos-y-datos)
- [Notas t√©cnicas](#notas-t√©cnicas)
- [Estado del proyecto](#estado-del-proyecto)
- [Contribuir](#contribuir)
- [Licencia](#licencia)

---

## Descripci√≥n

Este proyecto implementa un **clasificador en cascada** que:

1. Determina si una imagen es **food** o **no_food**
2. Si es *food*, la clasifica entre **hasta 121 tipos de comida**
3. Si es *no_food*, la clasifica en **22 categor√≠as contextuales**
4. Asocia predicciones de comida con **informaci√≥n nutricional estimada**
5. Expone el sistema mediante **API REST (FastAPI)** y **UI (Gradio)**


---

## Arquitectura
```text
Imagen
‚îÇ
‚ñº
[ Binary Classifier ]
‚îÇ
‚îú‚îÄ‚îÄ food ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ [ Food Classifier (121 clases) ] ‚îÄ‚ñ∂ Nutrici√≥n
‚îÇ
‚îî‚îÄ‚îÄ no_food ‚îÄ‚îÄ‚ñ∂ [ No-Food Classifier (22 clases) ]
```

### Detalles t√©cnicos
- Backbone: **EfficientNet (timm)**
- Transfer learning + fine-tuning
- Albumentations para data augmentation
- Mixed Precision Training (AMP)
- AdamW + class weighting
- Inferencia con umbral configurable

---

## Diagrama de Flujo


```mermaid
flowchart TD
    INICIO["Inicio train.py"]
    PARSE_ARGS["Parsear argumentos CLI"]
    CHECK_MODE["Validar modo: binary/food/nofood"]
    PREPARE_DATA["Preparar datasets<br/>Food-101 + No-Food"]
    COPY_TMP{"Copy to tmp?<br/>--copy_to_tmp"}
    
    INICIO --> PARSE_ARGS
    PARSE_ARGS --> CHECK_MODE
    CHECK_MODE --> PREPARE_DATA
    
    PREPARE_DATA --> COPY_TMP
    COPY_TMP -->|S√≠| COPY_DONE["Copiar dataset a /tmp"]
    COPY_TMP -->|No| LOAD_TRANSFORMS["Cargar transforms<br/>Albumentations"]
    COPY_DONE --> LOAD_TRANSFORMS
    
    LOAD_TRANSFORMS --> CREATE_DATASETS["Crear datasets:<br/>AlbumentationsImageFolder<br/>BinaryFoodNoFoodDataset"]
    CREATE_DATASETS --> COMPUTE_WEIGHTS["Calcular pesos<br/>WeightedRandomSampler"]
    COMPUTE_WEIGHTS --> CREATE_DATALOADERS["DataLoaders:<br/>train/val<br/>workers=2/0 en Colab"]

    subgraph TRAINING_LOOP["üîÑ Bucle de Entrenamiento"]
        EPOCH_START["√âpoca N"]
        TRAIN_EPOCH["train_epoch()<br/>AMP + AdamW<br/>CE Loss"]
        EVAL_VAL["eval_model()<br/>Accuracy en val"]
        SAVE_CHECKPOINT{"Mejor acc?<br/>Guardar checkpoint"}
    end

    CREATE_DATALOADERS --> EPOCH_START
    EPOCH_START --> TRAIN_EPOCH
    TRAIN_EPOCH --> EVAL_VAL
    EVAL_VAL --> SAVE_CHECKPOINT
    SAVE_CHECKPOINT --> EPOCH_FIN["Fin √©poca"]
    EPOCH_FIN -.->|Siguiente| EPOCH_START

    EPOCH_FIN --> END_TRAINING["Fin entrenamiento<br/>Best acc reportado"]

    PARSE_ARGS -.->|Error| ERROR_ARGS["Error: faltan argumentos<br/>--mode requerido"]
    CHECK_MODE -.->|Error| ERROR_MODE["Error: modo no soportado"]
    CREATE_DATASETS -.->|Error| ERROR_DATA["Error: dataset vac√≠o"]
    TRAINING_LOOP -.->|Excepci√≥n| SAVE_CRASH["crash_partial_{mode}.pth"]

    classDef inicio fill:#a3c1f7,stroke:#333,stroke-width:2px
    classDef proceso fill:#f7efb3,stroke:#333,stroke-width:2px
    classDef decision fill:#ffd5a3,stroke:#333,stroke-width:2px
    classDef error fill:#d9787a,stroke:#a25757,stroke-width:2px
    classDef final fill:#688654,stroke:#333,stroke-width:3px

    class INICIO,EPOCH_START,END_TRAINING inicio
    class PREPARE_DATA,LOAD_TRANSFORMS,CREATE_DATASETS,COMPUTE_WEIGHTS,CREATE_DATALOADERS proceso
    class COPY_TMP,SAVE_CHECKPOINT decision
    class TRAIN_EPOCH,EVAL_VAL final
    class ERROR_ARGS,ERROR_MODE,ERROR_DATA,SAVE_CRASH error
```



---

## Caracter√≠sticas

- Clasificaci√≥n en cascada (binario ‚Üí multiclase)
- Entrenamiento configurable por modo
- Inferencia local o v√≠a API
-  Estimaci√≥n nutricional desde CSV
-  UI interactiva con Gradio
- ‚úÖ Docker listo para despliegue
- ‚úÖ Compatible con Google Colab

---

## Estructura del repositorio

```text
.
‚îú‚îÄ‚îÄ app_fastapi.py          # API REST
‚îú‚îÄ‚îÄ app_gradio.py           # UI Gradio (cliente o local)
‚îú‚îÄ‚îÄ main.py                 # Demo local Gradio
‚îú‚îÄ‚îÄ train.py                # Entrenamiento (binary / food / nofood)
‚îú‚îÄ‚îÄ inference_cascade.py    # Pipeline de inferencia
‚îú‚îÄ‚îÄ utils.py                # Utilidades comunes
‚îú‚îÄ‚îÄ models/                 # clases.txt, checkpoints
‚îú‚îÄ‚îÄ model/                  # modelos .pth
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ nutrition_food101_merged.csv
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```


---

## Requisitos

- Python ‚â• 3.9
- PyTorch
- GPU recomendada (para entrenamiento)

Principales librer√≠as:
- `torch`, `timm`
- `albumentations`
- `fastapi`, `uvicorn`
- `gradio`
- `pandas`, `numpy`, `scikit-learn`

---

## Instalaci√≥n

```bash
pip install -r requirements.txt
```

Instalaci√≥n manual m√≠nima:
```
pip install timm==0.9.2 albumentations==1.3.0 torchmetrics scikit-learn
pip install fastapi uvicorn gradio pandas numpy
```
---

---

## Entrenamiento

El script `train.py` soporta tres modos:

- `binary`
- `food`
- `nofood`

### Ejemplo (binario)

```bash
python train.py \
  --mode binary \
  --data_dir /path/Food-101 \
  --no_food_dir /path/no_food \
  --model_dir ./models \
  --epochs 10 \
  --bs 32 \
  --img_size 192

```

### Diagrama de Flujo del Entrenamiento

text
## üèãÔ∏è Diagrama de Flujo del Entrenamiento (Sin Errores)

```mermaid
flowchart TD
    INICIO["Inicio train.py"]
    PARSE_ARGS["Parsear argumentos CLI"]
    CHECK_MODE["Validar modo"]
    PREPARE_DATA["Preparar datasets Food-101"]
    COPY_TMP{"Copy to tmp?"}
    
    INICIO --> PARSE_ARGS
    PARSE_ARGS --> CHECK_MODE
    CHECK_MODE --> PREPARE_DATA
    
    PREPARE_DATA --> COPY_TMP
    COPY_TMP -->|S√≠| COPY_DONE["Copiar a /tmp"]
    COPY_TMP -->|No| LOAD_TRANSFORMS["Cargar Albumentations"]
    COPY_DONE --> LOAD_TRANSFORMS
    
    LOAD_TRANSFORMS --> CREATE_DATASETS["Datasets train/val"]
    CREATE_DATASETS --> COMPUTE_WEIGHTS["WeightedRandomSampler"]
    COMPUTE_WEIGHTS --> CREATE_DATALOADERS["DataLoaders"]

    subgraph TRAINING_LOOP["Bucle de Entrenamiento"]
        EPOCH_START["Epoca N"]
        TRAIN_EPOCH["train_epoch AMP+AdamW"]
        EVAL_VAL["eval_model val acc"]
        SAVE_CHECKPOINT["Guardar best_model"]
    end

    CREATE_DATALOADERS --> EPOCH_START
    EPOCH_START --> TRAIN_EPOCH
    TRAIN_EPOCH --> EVAL_VAL
    EVAL_VAL --> SAVE_CHECKPOINT
    SAVE_CHECKPOINT --> EPOCH_FIN["Fin epoca"]
    EPOCH_FIN -.->|Next| EPOCH_START
    EPOCH_FIN --> END_TRAINING["Best acc guardado"]

    classDef inicio fill:#a3c1f7
    classDef proceso fill:#f7efb3
    classDef decision fill:#ffd5a3
    classDef loop fill:#c9e4a1

    class INICIO,END_TRAINING inicio
    class PREPARE_DATA,LOAD_TRANSFORMS,CREATE_DATASETS,COMPUTE_WEIGHTS,CREATE_DATALOADERS proceso
    class COPY_TMP,SAVE_CHECKPOINT decision
    class EPOCH_START,EPOCH_FIN loop
```

---

##  Inferencia

```from inference_cascade import predict_single

result = predict_single("image.jpg", bin_thresh=0.5)
print(result)
```
Salida t√≠pica: (food, "pizza", 0.94)

---

## Entrenamiento

El script `train.py` soporta tres modos:

- `binary`
- `food`
- `nofood`

### Ejemplo (binario)

```bash
python train.py \
  --mode binary \
  --data_dir /path/Food-101 \
  --no_food_dir /path/no_food \
  --model_dir ./models \
  --epochs 10 \
  --bs 32 \
  --img_size 192
Los modelos y archivos de clases se guardan autom√°ticamente en --model_dir.
```

---

## Inferencia
Inferencia en cascada sobre una imagen:
```
from inference_cascade import predict_single

result = predict_single("image.jpg", bin_thresh=0.5)
print(result)
```
Salida t√≠pica:
```
(food, "pizza", 0.94)
```
---

## API (FastAPI)
Lanzar servidor
```
uvicorn app_fastapi:app --host 0.0.0.0 --port 8000
Endpoint principal
POST /predict

curl -X POST "http://localhost:8000/predict?topk=3" \
  -F "file=@image.jpg"
```
Devuelve:
```
Predicci√≥n top-k
```
Probabilidades

Informaci√≥n nutricional estimada (si aplica)

---

## Interfaz Gradio
python app_gradio.py
# 
python main.py
Opcionalmente, puede consumir la API remota configurando:

export BACKEND_URL="http://localhost:8000"

---

## Docker

Construir imagen

docker build -t food-classifier .
Ejecutar
docker run -p 8000:8000 food-classifier
Puedes montar vol√∫menes para modelos y datos si lo prefieres.

## Modelos y datos

- Food: Food-101 + platos adicionales (121 clases)
- No-food: 22 categor√≠as
- Nutrici√≥n: CSV con calor√≠as y macronutrientes estimados

> Aseg√∫rate de que `classes_*.txt` coincidan exactamente con los checkpoints usados.

---

## Notas t√©cnicas

- Copiar datasets desde Google Drive a disco local mejora significativamente el rendimiento
- En Colab, usar `workers=0` si hay bloqueos del `DataLoader`
- Los checkpoints pueden requerir limpieza de prefijos (`module.`)
- El proyecto utiliza label smoothing por defecto

---

##  Estado del proyecto

- üü° Pre-alfa
- C√≥digo funcional
- Falta hardening para producci√≥n (tests, validaciones, seguridad)
- Ideal para investigaci√≥n, demos y prototipos

---

## Contribuir

¬°Las contribuciones son bienvenidas! Si quieres mejorar este proyecto:

1. Abre un **issue** para proponer cambios, reportar bugs o sugerir mejoras.
2. Crea una nueva rama a partir de `main`:
   - `feature/nombre-funcionalidad`
   - `fix/descripcion-bug`
3. Realiza tus cambios asegur√°ndote de que:
   - El c√≥digo sea claro y est√© documentado
   - No rompa funcionalidades existentes
4. Env√≠a un **Pull Request** describiendo claramente:
   - Qu√© se ha cambiado
   - Por qu√© es necesario
   - C√≥mo probarlo

> Sugerencia: si el cambio es grande, abre primero un issue para discutirlo.

---

## üìÑ Licencia

Este proyecto se publicar√° bajo licencia **MIT**, lo que permite su uso, modificaci√≥n y distribuci√≥n libremente, siempre que se mantenga la atribuci√≥n al autor.












